{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MJMortensonWarwick/DSML2223/blob/main/1_1_Regression_(Stats_vs_ML).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQaQTTM8HkIC"
   },
   "source": [
    "# Linear Regression in Scikit-Learn\n",
    "\n",
    "### Traditional Statistics Approach\n",
    "As above, its a Linear Regression tutorial (yay), using the popular (indeed some may say seminal) machine learning library scikit-learn. As per usual, we will start by installing and importing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TsZu7TTCHVTF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd  \n",
    "import seaborn as sns \n",
    "\n",
    "# Only works on Jupyter/Anaconda\n",
    "%matplotlib inline  \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRyyQotGIHTE"
   },
   "source": [
    "We will also use one of the inbuilt datasets included with _scikit\\-learn_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPefRRmqIKfa",
    "outputId": "f3a6c690-d304-4083-8967-6173218a20b6"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import a standard dataset - the Boston house price index\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_boston\n\u001b[1;32m      3\u001b[0m boston_dataset \u001b[38;5;241m=\u001b[39m load_boston()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/datasets/__init__.py:157\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_boston\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    109\u001b[0m     msg \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124m        `load_boston` has been removed from scikit-learn since version 1.2.\u001b[39m\n\u001b[1;32m    111\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124m        <https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\u001b[39m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name]\n",
      "\u001b[0;31mImportError\u001b[0m: \n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n"
     ]
    }
   ],
   "source": [
    "# import a standard dataset - the Boston house price index\n",
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qWvUfZNIOJj"
   },
   "source": [
    "As the comment says, this is a well known dataset ... indeed Andrew Ng's first dataset in his first lecture of the first mainstream MOOC in machine learning. Let's look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WzUax3AISeU",
    "outputId": "c7d2fd38-f78a-4e73-cd32-b07e7fe10d57"
   },
   "outputs": [],
   "source": [
    "# show the dataset\n",
    "print(boston_dataset)\n",
    "\n",
    "# print a return space\n",
    "print('\\n')\n",
    "\n",
    "# show the keys\n",
    "print(boston_dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCjjVtOoIWMH"
   },
   "source": [
    "As we can see this is actually a dictionary with 'data' (the X's we can use), 'target' (the Y's), 'feature_names' (the names of all of the columns that represent X), 'DESCR' (a description of the data) and 'filename' (I'll let you guess). With this in mind let's add the X's to a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2qL857JTIcAo",
    "outputId": "dbc05667-e703-4bda-93b2-ce73a2c22d7b"
   },
   "outputs": [],
   "source": [
    "# convert to data frame using Pandas\n",
    "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nX2xbkuMIjAv"
   },
   "source": [
    "We will also create a variable for the Y value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2antsWmIluJ",
    "outputId": "126fd440-3147-4e76-9579-dd0092993069"
   },
   "outputs": [],
   "source": [
    "# create a separate Y value\n",
    "boston_Y = boston_dataset.target\n",
    "boston_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWQvuZrLIohs"
   },
   "source": [
    "From here we can build our model. Let's recall that the model we want is of the form:\n",
    "\n",
    "$ Y = a + b_1x_1 + b_2x_2 + [...] + b_13x_13 + e$\n",
    "\n",
    "Where \n",
    "$Y$ is our target variable (boston_Y), $a$ is the intercept, the various $b$ values (1 to 13) represent the effect of the corresponding $x$ values (1 to 13) on the slope and $e$ is the error.\n",
    "\n",
    "We start by defining a model and 'fitting' it to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RWgZvWbJQRh"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_model = LinearRegression()\n",
    "\n",
    "# fit the model to the training data\n",
    "lin_model_fit = lin_model.fit(boston, boston_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viHQJLzYJTwF"
   },
   "source": [
    "Here we have created a Linear Regression object (lin_model) and then an object based on fitting it to our data. In other words, lin_model_fit is the Linear Regression process applied to our data.\n",
    "\n",
    "From this object we can establish the remainder of our formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrdKjYmTJWpP",
    "outputId": "b02221a3-5023-45e1-a958-ed79d3b6d674"
   },
   "outputs": [],
   "source": [
    "# print the alpha value of the model (intercept)\n",
    "print(\"Alpha/intercept (a)\")\n",
    "print(lin_model_fit.intercept_)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# print the beta values of the model (co-efficients)\n",
    "betas = lin_model_fit.coef_\n",
    "counter = 0\n",
    "for col in boston.columns:\n",
    "    if counter == 0:\n",
    "        print(\"Beta weights/co-efficients (b1 to b13)\")\n",
    "        print(\"-----------------------------------------\")\n",
    "    print(col + \": \" + str(round(betas[counter], 4)))\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIIqlYGlJbUd"
   },
   "source": [
    "We can also calculate the root mean squared error (RMSE) and the $R^2$ score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNEanhiMJhgv",
    "outputId": "05c3f68f-83e6-4ae0-ea75-932fd9ae0697"
   },
   "outputs": [],
   "source": [
    "# predict every Y value in the dataset\n",
    "boston_predict = lin_model_fit.predict(boston)\n",
    "\n",
    "# calculate RMSE (root mean square error) and R^2 (predictive power)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rmse = (np.sqrt(mean_squared_error(boston_Y, boston_predict)))\n",
    "r2 = r2_score(boston_Y, boston_predict)\n",
    "\n",
    "# print the performance metrics\n",
    "print(\"Model performance\")\n",
    "print(\"--------------------------------------\")\n",
    "print(f'RMSE is {rmse}')\n",
    "print(f'R2 score is {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GpM1_PHJlp9"
   },
   "source": [
    "Overall this is a good model - \n",
    " scores above 0.7 are considered very much publishable/successful when building regression models! RMSE, the square root of the sum of each error term squared, is more domain specific (and often used for module comparison), but in this case means our forecasted property prices are incorrect by, on average, \\$4,679. Given that many properties sell for more than $50,000 this is not too bad.\n",
    "\n",
    "Keep scrolling, we'll next relook at this with a more \"machine learning\" mindset :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00Vfvi8tJzqi"
   },
   "source": [
    "### Machine Learning Approach\n",
    "We'll redo our linear regression and this time we'll make it more \"machine-learning-y\". Actually, arguably, all we need to do is via splitting our data into training and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLU_JYeFJ7bJ",
    "outputId": "0954c825-28fe-459b-e0f4-689035c8d220"
   },
   "outputs": [],
   "source": [
    "# split data into training and test\n",
    "from sklearn.model_selection  import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(boston, boston_Y, test_size = 0.2)\n",
    "\n",
    "# print the shapes to check everything is OK\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NW_z8eufKDBl"
   },
   "source": [
    "The \"shapes\" shown here are number of rows by number of columns ... i.e. the shape of \"X_train\" is 404 rows by 13 columns. We'd expect the 13 columns (13 X's), and we can quickly do some math on the 506 row numbers ... \n",
    " ... to see that 404 is rougly 80 % of the data (our \"test_size\" was 20% so our training data should be 80%) and that this all looks correct. The Y \"shapes\" show only rows but this is because we have only 1x value (1x column).\n",
    "\n",
    "Using these subsets we can train the Linear Regression model on \"X_train\" and \"Y_train\", and then use this model to predict \"X_test\". If we can compare the predictions on \"X_test\" with the real values of \"Y_test\" this gives us a measure of how well our computer has learned to predict house prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2soXyjhfKF1x",
    "outputId": "0f788900-0c00-4887-f972-f05e11674500"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_model = LinearRegression()\n",
    "\n",
    "# fit the model to the training data\n",
    "lin_model_fit = lin_model.fit(X_train, Y_train)\n",
    "\n",
    "# predict the data\n",
    "boston_predict = lin_model_fit.predict(X_test)\n",
    "\n",
    "# calculate RMSE (root mean square error) and R^2 (predictive power)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, boston_predict)))\n",
    "r2 = r2_score(Y_test, boston_predict)\n",
    "\n",
    "# print the performance metrics\n",
    "print(\"Model performance\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxOOXeZfKJjf"
   },
   "source": [
    "Compared to the previous Notebook our RMSE is lower and \n",
    " higher (i.e. better in both cases)! This is a little suprising but probably just chance on how the data was split (random error means the metrics are superior). However, we can conclude that this hasn't made our model worse.\n",
    "\n",
    "What it has done, however, is meant we have a model that is tested against its ability to make predictions on unseen data ... i.e. that it has learned about the process of predicting house prices and can do this well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eaFknfAKMCj"
   },
   "source": [
    "#### L1 Regularisation (LASSO)\n",
    "$L1$ Regression is performed in much the same way as Linear Regression. We have one other value (a hyperparameter - more on these later) of $\\alpha$ which determines how much influence the \n",
    " penalty has on how the line is fit in the model. We will dodge the issue of what this should be for now and just randomly set it as 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B_7UJMGgKdUH",
    "outputId": "6cc16701-0607-4391-dfaa-d9fed97a00a8"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "l1_model = Lasso(alpha=0.5)\n",
    "\n",
    "# fit the model to the training data\n",
    "l1_model_fit = l1_model.fit(X_train, Y_train)\n",
    "\n",
    "# predict the data\n",
    "boston_predict = l1_model_fit.predict(X_test)\n",
    "\n",
    "# calculate RMSE (root mean square error) and R^2 (predictive power)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, boston_predict)))\n",
    "r2 = r2_score(Y_test, boston_predict)\n",
    "\n",
    "# print the performance metrics\n",
    "print(\"Model performance\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HA-xdePtKhGv"
   },
   "source": [
    "Performance is slightly lower than for our normal linear model. However... this is somewhat to be expected and actually performance is only slightly worse. This may be a small price to pay for ensuring that our model is a little more robust to changing data.\n",
    "\n",
    "Where we should see a much more fundamental difference is in the beta-weights/coefficients of the two models (the $b$ values). Let's compare the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xAW2CdmaKlsL",
    "outputId": "2d45eafb-497c-466a-f758-d78d8dbe3b54"
   },
   "outputs": [],
   "source": [
    "# print the beta values of the model (co-efficients)\n",
    "betas = lin_model_fit.coef_\n",
    "counter = 0\n",
    "for col in boston.columns:\n",
    "    if counter == 0:\n",
    "        print(\"Beta weights/co-efficients - UNREGULARISED\")\n",
    "        print(\"-----------------------------------------\")\n",
    "    print(col + \": \" + str(round(betas[counter], 4)))\n",
    "    counter +=1\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "# print the beta values of the model (co-efficients)\n",
    "betas_l1 = l1_model_fit.coef_\n",
    "counter = 0\n",
    "for col in boston.columns:\n",
    "    if counter == 0:\n",
    "        print(\"Beta weights/co-efficients - LASSO\")\n",
    "        print(\"-----------------------------------------\")\n",
    "    print(col + \": \" + str(round(betas_l1[counter], 4)))\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDuK4R_jKsIX"
   },
   "source": [
    "As we can see some of the beta weights are now 0 (\"INDUS\", \"CHAS\" and \"NOX\" - of which \"CHAS\" and \"NOX\" were fairly large weights in the original model). We have effectively removed these features (X's) from the model - they are now (for instance) $0 * INDUS$ which will obviously be zero and therefore won't change the calculation of $Y$. We have performed feature selection - removing X's from the model.\n",
    "\n",
    "We have also minimised the impact (weight) of all the X's. For instance, \"RM\" had a beta of 3.77 in the original model and only 0.74 in the LASSO model.\n",
    "\n",
    "Overall we have made the model less reliant on certain features and removed others entirely (reducing model complexity). Both these elements mean our model is more robust/protected against over-fitting ... and the cost is only 0.05 in terms of $R^2$ score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IrhbFSdLCXA"
   },
   "source": [
    "#### L2 Regularisation (Ridge)\n",
    "$L2$ regularisation is performed in a very similar way in scikit-learn ... and again we will set the hyperparameter $\\alpha$ to the arbitrary value of 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tF7TGDvkLHuo",
    "outputId": "14fed84a-ebbb-4011-ad07-4bde3592a664"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "l2_model = Ridge(alpha=0.75)\n",
    "\n",
    "# fit the model to the training data\n",
    "l2_model_fit = l2_model.fit(X_train, Y_train)\n",
    "\n",
    "# predict the data\n",
    "boston_predict = l2_model_fit.predict(X_test)\n",
    "\n",
    "# calculate RMSE (root mean square error) and R^2 (predictive power)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, boston_predict)))\n",
    "r2 = r2_score(Y_test, boston_predict)\n",
    "\n",
    "# print the performance metrics\n",
    "print(\"Model performance\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_y7nSsfLLLGc"
   },
   "source": [
    "Here we have model performance that slightly improves upon the original model ... while also adding regularisation protection. Let's compare the three beta weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FET5ez6oLPif",
    "outputId": "07cf6dce-8dfa-49fa-cda0-9a631b9a380f"
   },
   "outputs": [],
   "source": [
    "# print the beta values of the model (co-efficients)\n",
    "betas = lin_model_fit.coef_\n",
    "counter = 0\n",
    "for col in boston.columns:\n",
    "    if counter == 0:\n",
    "        print(\"Beta weights/co-efficients - UNREGULARISED\")\n",
    "        print(\"-----------------------------------------\")\n",
    "    print(col + \": \" + str(round(betas[counter], 4)))\n",
    "    counter +=1\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "# print the beta values of the model (co-efficients)\n",
    "betas_l1 = l1_model_fit.coef_\n",
    "counter = 0\n",
    "for col in boston.columns:\n",
    "    if counter == 0:\n",
    "        print(\"Beta weights/co-efficients - LASSO\")\n",
    "        print(\"-----------------------------------------\")\n",
    "    print(col + \": \" + str(round(betas_l1[counter], 4)))\n",
    "    counter +=1\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "# print the beta values of the model (co-efficients)\n",
    "betas_l2 = l2_model_fit.coef_\n",
    "counter = 0\n",
    "for col in boston.columns:\n",
    "    if counter == 0:\n",
    "        print(\"Beta weights/co-efficients - RIDGE\")\n",
    "        print(\"-----------------------------------------\")\n",
    "    print(col + \": \" + str(round(betas_l2[counter], 4)))\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4w6jxYQLU46"
   },
   "source": [
    "As with L1/LASSO regression all our beta values are lower than in the original model - and therefore each feature is less influential. However, none have been reduced to zero. L2 cannot perform feature selection (deleting X's) unlike with L1.\n",
    "\n",
    "So better performance and regularisation added - seems like a good deal right? However, before we call it a day we have one other regularisation method we may try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtgXlvr4LafY"
   },
   "source": [
    "#### ElasticNet\n",
    "ElasticNet uses both $L1$ and $L2$ regularisation. We now have an additonal value to set (hyperparameter - still going to come back to these) the l1_ratio. As the name suggests the l1_ratio determines the proportion that is L1 versus L2 so \"1\" would be just L1 and \"0\" would just be L2. We'll arbitrarily go with 0.5 again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXbUNI6HLg74",
    "outputId": "473a72c3-ead1-4ec8-aa80-bb71739ead89"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "enet_model = ElasticNet(alpha=0.5, l1_ratio=0.25)\n",
    "\n",
    "# fit the model to the training data\n",
    "enet_model_fit = enet_model.fit(X_train, Y_train)\n",
    "\n",
    "# predict the data\n",
    "boston_predict = enet_model_fit.predict(X_test)\n",
    "\n",
    "# calculate RMSE (root mean square error) and R^2 (predictive power)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, boston_predict)))\n",
    "r2 = r2_score(Y_test, boston_predict)\n",
    "\n",
    "# print the performance metrics\n",
    "print(\"Model performance\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lhed1C_LpO6"
   },
   "source": [
    "Unsurprisingly the result is somewhere between the results of L1 and L2. Let's also check the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rYoweEwlLZJv",
    "outputId": "08e847cf-dc44-4745-bf0a-564101bbfd96"
   },
   "outputs": [],
   "source": [
    "# print the beta values of the model (co-efficients)\n",
    "betas = lin_model_fit.coef_\n",
    "counter = 0\n",
    "for col in boston.columns:\n",
    "    if counter == 0:\n",
    "        print(\"Beta weights/co-efficients - UNREGULARISED\")\n",
    "        print(\"-----------------------------------------\")\n",
    "    print(col + \": \" + str(round(betas[counter], 4)))\n",
    "    counter +=1\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "# print the beta values of the model (co-efficients)\n",
    "betas_l1 = l1_model_fit.coef_\n",
    "counter = 0\n",
    "for col in boston.columns:\n",
    "    if counter == 0:\n",
    "        print(\"Beta weights/co-efficients - LASSO\")\n",
    "        print(\"-----------------------------------------\")\n",
    "    print(col + \": \" + str(round(betas_l1[counter], 4)))\n",
    "    counter +=1\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "# print the beta values of the model (co-efficients)\n",
    "betas_l2 = l2_model_fit.coef_\n",
    "counter = 0\n",
    "for col in boston.columns:\n",
    "    if counter == 0:\n",
    "        print(\"Beta weights/co-efficients - RIDGE\")\n",
    "        print(\"-----------------------------------------\")\n",
    "    print(col + \": \" + str(round(betas_l2[counter], 4)))\n",
    "    counter +=1\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "# print the beta values of the model (co-efficients)\n",
    "betas_enet = enet_model_fit.coef_\n",
    "counter = 0\n",
    "for col in boston.columns:\n",
    "    if counter == 0:\n",
    "        print(\"Beta weights/co-efficients - ELASTICNET\")\n",
    "        print(\"-----------------------------------------\")\n",
    "    print(col + \": \" + str(round(betas_enet[counter], 4)))\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Du6_D6N3LxYD"
   },
   "source": [
    "Again, as we may expect, the results are somewhere between the two. \"CHAS\" and \"NOX\" have betas of zero (have been removed) but not \"INDUS\". All other beta weights are reduced to somewhere between the L1 and L2 models.\n",
    "\n",
    "**BONUS! Which is best?**\n",
    "Hahahahaha ... you know what I'm going to say:\n",
    "\n",
    "## IT DEPENDS!\n",
    "If you are not worried about overfitting use the original model (but if you don't care about overfitting are you doing ML?). If you have a lot of features and want some removed you may use L1 or Elastic Net. If you care most about performance use the L2 model. In this case I'd probably go with L2 as there aren't a lot of features and the performance is best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJmNZoMEjsuR"
   },
   "source": [
    "### Hyperparameter Optimisation\n",
    "What are the right values for the hyperparameters? In this case we just don't know, but we can try to optimise a solution!\n",
    "\n",
    "The following hyperparameters should be optimised:\n",
    "1.   Linear Regression - no hyperparameters\n",
    "2.   Lasso Regression - $\\alpha$ (alpha)\n",
    "2.   Ridge Regression - $\\alpha$ (alpha)\n",
    "2.   ElasticNet - $\\alpha$ (alpha) and $L1$ ratio (how much of the penalty should be $L1$ and how much $L2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxWiUyL1jr08",
    "outputId": "67f7144e-776f-48f5-8043-22b1bf2cc6b3"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_parameters = [{'alpha': [0.25, 0.5, 0.75]}] # test the listed alpha values\n",
    "\n",
    "scores = ['r2'] # test for R^2\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyperparameters for %s\" % score)\n",
    "    print(\"\\n\")\n",
    "    clf = GridSearchCV(Lasso(), tuned_parameters, cv=5,\n",
    "                       scoring= score)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"Best parameters set found on the training set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLnu3x1dkx2w"
   },
   "source": [
    "Here we have decide (fairly arbitarily) to test for $R^2$. For comparison sake we could also test for _RMSE_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WqnBI5A-lBb1",
    "outputId": "3d06166e-de8a-4d51-c471-89087339ac9b"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_parameters = [{'alpha': [0.25, 0.5, 0.75]}] # test the listed alpha values\n",
    "\n",
    "scores = ['neg_root_mean_squared_error'] # test for RMSE\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyperparameters for %s\" % score)\n",
    "    print(\"\\n\")\n",
    "    clf = GridSearchCV(Lasso(), tuned_parameters, cv=5,\n",
    "                       scoring= score)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"Best parameters set found on the training set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAZpUZidlM5w"
   },
   "source": [
    "In this case there is the same result. Let's also test Ridge (L2) and ElasticNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGF7ZPeklXhD",
    "outputId": "43494aeb-c33c-4716-efcf-05ada7dce81d"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "tuned_parameters = [{'alpha': [0.25, 0.5, 0.75]}] # test the listed alpha values\n",
    "\n",
    "scores = ['r2'] # test for RMSE and R^2\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyperparameters for %s\" % score)\n",
    "    print(\"\\n\")\n",
    "    clf = GridSearchCV(Ridge(), tuned_parameters, cv=5,\n",
    "                       scoring= score)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"Best parameters set found on the training set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "im8o2wEnlLsF",
    "outputId": "21a97426-0002-4f3e-aeab-afd7a351475e"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "tuned_parameters = [{'alpha': [0.25, 0.5, 0.75], # test the listed alpha values\n",
    "                     'l1_ratio': [0.25, 0.5, 0.75]}] # test the listed L1 ratio values\n",
    "\n",
    "scores = ['neg_root_mean_squared_error', 'r2'] # test for RMSE and R^2\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyperparameters for %s\" % score)\n",
    "    print(\"\\n\")\n",
    "    clf = GridSearchCV(ElasticNet(), tuned_parameters, cv=5,\n",
    "                       scoring= score)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"Best parameters set found on the training set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R674aDIqltAI"
   },
   "source": [
    "We can see the \"best\" hyperparameters based on $R^2$. The final list is:\n",
    "1.   Linear Regression - still no hyperparameters\n",
    "2.   Lasso Regression - $\\alpha = 0.25$\n",
    "2.   Ridge Regression - $\\alpha = 0.25$\n",
    "2.   ElasticNet - $\\alpha = 0.25$ and $L1$ ratio $= 0.75$\n",
    "\n",
    "_Note, as we will disucss it is possible you may have different results!_\n",
    "\n",
    "With this now complete we can update the algorithms and build new models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKOquclvl7UC",
    "outputId": "bbba8c52-d5f7-4d54-b5a4-0cca466d6ab1"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# fit the LR model to the training data\n",
    "lin_model = LinearRegression()\n",
    "\n",
    "# fit the Lasso model\n",
    "l1_model = Lasso(alpha=0.25)\n",
    "\n",
    "# fit the Ridge model\n",
    "l2_model = Ridge(alpha=0.25)\n",
    "\n",
    "# fit the ElasticNet model\n",
    "enet = ElasticNet(alpha=0.25, l1_ratio=0.75)\n",
    "\n",
    "# make a list of models to iterate (loop) through\n",
    "models = [lin_model, l1_model, l2_model, enet]\n",
    "\n",
    "for model in models:\n",
    "  # fit model\n",
    "  fitted_model = model.fit(boston, boston_Y)\n",
    "\n",
    "  # predict every Y value in the dataset\n",
    "  boston_predict = fitted_model.predict(boston)\n",
    "\n",
    "  # calculate RMSE (root mean square error) and R^2 (predictive power)\n",
    "  from sklearn.metrics import mean_squared_error, r2_score\n",
    "  rmse = (np.sqrt(mean_squared_error(boston_Y, boston_predict)))\n",
    "  r2 = r2_score(boston_Y, boston_predict)\n",
    "\n",
    "  # print the performance metrics\n",
    "  print(f' {model} - Model performance')\n",
    "  print(\"--------------------------------------\")\n",
    "  print(f'RMSE is {rmse}')\n",
    "  print(f'R2 score is {r2}')\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVL6a7sbmLBY"
   },
   "source": [
    "Linear and Ridge still perform the best (around the same as before), but we can see that Lasso and ElasticNet have considerably improved. If we believe it is important to do \"feature selection\" (i.e. removing features from the model), we may well now prefer Lasso (L1) even with slightly lower $R^2$"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN+aWDJ95n7hQepkF8K/KzC",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
