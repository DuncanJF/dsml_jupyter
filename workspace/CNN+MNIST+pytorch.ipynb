{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639c1d63-6530-4443-9a14-6cc843ffa05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3e929f-c8c6-4b00-af22-0be924d7b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1: LOADING DATASET\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eeef554-5df2-40f8-b833-1381eebd1a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc17830a-2ed8-4eaf-b4cc-2a2f58ddb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40cb41f-febe-4551-ac15-81b6fd994b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e110f5-0f8a-47fb-a4a7-b532ee535937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2: MAKING DATASET ITERABLE\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc80b25b-ac2c-489d-b3f8-0dfde89878e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3: CREATE MODEL CLASS\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function 1: 784 --> 100\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity 1\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Linear function 2: 100 --> 100\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 2\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Linear function 3: 100 --> 100\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 3\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # Linear function 4 (readout): 100 --> 10\n",
    "        self.fc4 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function 1\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity 1\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        # Linear function 2\n",
    "        out = self.fc2(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        # Linear function 2\n",
    "        out = self.fc3(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        # Linear function 4 (readout)\n",
    "        out = self.fc4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "342dc065-9284-4654-b451-c236d87f61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 4: INSTANTIATE MODEL CLASS\n",
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d794fcb4-75ae-43d0-9e7c-1c270d099a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c36b7a66-4c33-49c7-a327-41ea961d21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23ab9c9a-3eff-40f2-bc56-baf9f6572530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e7f22-d28d-4836-955e-35478bb849eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1. Loss: 2.301947593688965. Accuracy: 9.739999771118164\n",
      "Iteration: 2. Loss: 2.297227382659912. Accuracy: 9.739999771118164\n",
      "Iteration: 4. Loss: 2.3088860511779785. Accuracy: 9.739999771118164\n",
      "Iteration: 8. Loss: 2.297534942626953. Accuracy: 9.789999961853027\n",
      "Iteration: 16. Loss: 2.294639825820923. Accuracy: 18.799999237060547\n",
      "Iteration: 32. Loss: 2.274282455444336. Accuracy: 26.209999084472656\n",
      "Iteration: 64. Loss: 2.232170343399048. Accuracy: 41.400001525878906\n",
      "Iteration: 128. Loss: 1.244429588317871. Accuracy: 58.599998474121094\n",
      "Iteration: 256. Loss: 0.5970173478126526. Accuracy: 84.77999877929688\n",
      "Iteration: 512. Loss: 0.3231336176395416. Accuracy: 90.33999633789062\n",
      "Iteration: 1024. Loss: 0.09996500611305237. Accuracy: 93.7699966430664\n",
      "Iteration: 2048. Loss: 0.06200489029288292. Accuracy: 96.1500015258789\n"
     ]
    }
   ],
   "source": [
    "#STEP 7: TRAIN THE MODEL\n",
    "iter = 0\n",
    "iteration_prints=[1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192]\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images with gradient accumulation capabilities\n",
    "        images = images.view(-1, 28*28).requires_grad_()\n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        #if iter % 500 == 0:\n",
    "        if iter in iteration_prints:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images with gradient accumulation capabilities\n",
    "                images = images.view(-1, 28*28).requires_grad_()\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602de70-843a-4d05-8be7-b91bff32b4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Training: %i\" % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9fac26-ce6a-4a46-a312-efb18d44ae9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9e333-5f72-4116-b9df-8cfa535024cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "clf = svm.SVC(gamma=0.001)\n",
    "\n",
    "# Split data into 50% train and 50% test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=False\n",
    ")\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the value of the digit on the test subset\n",
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8970f-870f-4dca-b0df-847d4f55a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, prediction in zip(axes, X_test, predicted):\n",
    "    ax.set_axis_off()\n",
    "    image = image.reshape(8, 8)\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f068b-a019-4fda-94fe-2535f336da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Classification report for classifier {clf}:\\n\"\n",
    "    f\"{metrics.classification_report(y_test, predicted)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fdff35-9215-42f8-a71e-7ab34de693b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, predicted)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a93cb6-747c-4d60-a076-f2f97b6413ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ground truth and predicted lists\n",
    "y_true = []\n",
    "y_pred = []\n",
    "cm = disp.confusion_matrix\n",
    "\n",
    "# For each cell in the confusion matrix, add the corresponding ground truths\n",
    "# and predictions to the lists\n",
    "for gt in range(len(cm)):\n",
    "    for pred in range(len(cm)):\n",
    "        y_true += [gt] * cm[gt][pred]\n",
    "        y_pred += [pred] * cm[gt][pred]\n",
    "\n",
    "print(\n",
    "    \"Classification report rebuilt from confusion matrix:\\n\"\n",
    "    f\"{metrics.classification_report(y_true, y_pred)}\\n\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
